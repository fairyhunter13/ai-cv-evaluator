name: Deploy

permissions:
  contents: read
  packages: write
  actions: write

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to (production only)'
        required: true
        default: 'production'
        type: choice
        options:
          - production
      target_ip:
        description: 'Override A record target IP for Cloudflare DNS sync (defaults to SSH_HOST secret)'
        required: false
        default: ''
        type: string
  push:
    tags:
      - 'v*'

concurrency:
  group: deploy-production
  cancel-in-progress: true

env:
  PRODUCTION_URL: https://ai-cv-evaluator.web.id
  DASHBOARD_URL: https://dashboard.ai-cv-evaluator.web.id

jobs:
  pre-deploy-checks:
    runs-on: ubuntu-latest
    outputs:
      should_deploy: ${{ steps.safety_check.outputs.should_deploy }}
      image_tag: ${{ steps.metadata.outputs.image_tag }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Extract metadata
        id: metadata
        run: |
          if [[ "${{ github.ref }}" == refs/tags/* ]]; then
            echo "image_tag=${GITHUB_REF#refs/tags/}" >> $GITHUB_OUTPUT
          else
            echo "image_tag=latest" >> $GITHUB_OUTPUT
          fi
          echo "commit_sha=${GITHUB_SHA:0:8}" >> $GITHUB_OUTPUT
      
      - name: Safety checks
        id: safety_check
        run: |
          # Check if this is a production deployment
          
          if [[ "${{ github.event.inputs.environment || 'production' }}" == "production" ]]; then
            # Ensure we're deploying a tagged version to production
            if [[ "${{ github.ref }}" != refs/tags/* ]]; then
              echo "Error: Production deployments require a git tag"
              exit 1
            fi
            
            # Check if tag follows semantic versioning
            if [[ ! "${{ github.ref_name }}" =~ ^v[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
              echo "Error: Production deployments require semantic version tags (v1.2.3)"
              exit 1
            fi
          fi
          echo "should_deploy=true" >> $GITHUB_OUTPUT
 
  security-gate:
    runs-on: ubuntu-latest
    needs: pre-deploy-checks
    if: needs.pre-deploy-checks.outputs.should_deploy == 'true'
    steps:
      - name: Check CI, Security Scans and Secrets Healthcheck for this commit
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          sudo apt-get update && sudo apt-get install -y jq

          OWNER="${GITHUB_REPOSITORY%/*}"
          REPO="${GITHUB_REPOSITORY#*/}"
          SHA="${GITHUB_SHA}"

          wait_for_workflow() {
            local wf_name="$1"
            # CI can be relatively heavy; allow up to ~10 minutes per attempt
            local max_attempts=10
            local sleep_seconds=60

            if [ "$wf_name" = "Docker Publish" ]; then
              max_attempts=30
              sleep_seconds=60
            fi

            echo "Waiting for workflow '$wf_name' on commit $SHA to succeed (max_attempts=$max_attempts, sleep_seconds=$sleep_seconds)..."

            for attempt in $(seq 1 "$max_attempts"); do
              echo "Attempt $attempt/$max_attempts for '$wf_name'..."

              runs_json=$(curl -sS \
                -H "Authorization: Bearer ${GITHUB_TOKEN}" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/repos/${OWNER}/${REPO}/actions/runs?per_page=100")

              local match
              match=$(echo "$runs_json" | jq -r --arg sha "$SHA" --arg name "$wf_name" '
                .workflow_runs
                | map(
                    select(
                      .name == $name
                      and .head_sha == $sha
                      and .event == "push"
                      and (if $name == "CI" then .head_branch == "main" else true end)
                    )
                  )
                | sort_by(.run_number) | last // empty
              ')

              if [ -z "$match" ]; then
                echo "No '$wf_name' run found yet for commit $SHA."
              else
                local status conclusion html_url event head_branch run_number
                status=$(echo "$match" | jq -r '.status')
                conclusion=$(echo "$match" | jq -r '.conclusion // empty')
                html_url=$(echo "$match" | jq -r '.html_url')
                event=$(echo "$match" | jq -r '.event')
                head_branch=$(echo "$match" | jq -r '.head_branch // "(none)"')
                run_number=$(echo "$match" | jq -r '.run_number // 0')

                echo "Found $wf_name run: $html_url"
                echo "Status: $status, conclusion: ${conclusion:-'(none)'}, event: $event, branch: $head_branch, run_number: $run_number"

                if [ "$status" = "completed" ]; then
                  if [ "$conclusion" = "success" ]; then
                    echo "$wf_name succeeded for commit $SHA."
                    return 0
                  else
                    echo "$wf_name did not succeed (conclusion=$conclusion); blocking deploy."
                    return 1
                  fi
                fi
              fi

              if [ "$attempt" -lt "$max_attempts" ]; then
                echo "Waiting ${sleep_seconds}s before re-checking '$wf_name'..."
                sleep "$sleep_seconds"
              fi
            done

            echo "Timed out waiting for '$wf_name' workflow to complete successfully for commit $SHA."
            return 2
          }

          print_workflow_status() {
            local wf_name="$1"

            echo "Checking latest '$wf_name' workflow run for commit $SHA (non-blocking)..."

            runs_json=$(curl -sS \
              -H "Authorization: Bearer ${GITHUB_TOKEN}" \
              -H "Accept: application/vnd.github+json" \
              "https://api.github.com/repos/${OWNER}/${REPO}/actions/runs?per_page=100")

            local match
            match=$(echo "$runs_json" | jq -r --arg sha "$SHA" --arg name "$wf_name" '
              .workflow_runs
              | map(select(.name == $name and .head_sha == $sha))
              | sort_by(.run_number) | last // empty
            ')

            if [ -z "$match" ]; then
              echo "[WARN] No '$wf_name' run found for commit $SHA. This check will not block deployment but please verify manually if needed."
              return 0
            fi

            local status conclusion html_url event head_branch run_number
            status=$(echo "$match" | jq -r '.status')
            conclusion=$(echo "$match" | jq -r '.conclusion // empty')
            html_url=$(echo "$match" | jq -r '.html_url')
            event=$(echo "$match" | jq -r '.event')
            head_branch=$(echo "$match" | jq -r '.head_branch // "(none)"')
            run_number=$(echo "$match" | jq -r '.run_number // 0')

            echo "Latest $wf_name run: $html_url"
            echo "Status: $status, conclusion: ${conclusion:-'(none)'}, event: $event, branch: $head_branch, run_number: $run_number"

            if [ "$status" = "completed" ] && [ "$conclusion" != "success" ]; then
              echo "[WARN] '$wf_name' completed with conclusion='$conclusion'. Deployment will continue, but you should review this run."
            fi
          }

          # Hard gates: CI and Docker Publish must be successful for this commit
          ci_result=0
          if ! wait_for_workflow "CI"; then
            ci_result=$?
          fi

          if [ "$ci_result" -eq 1 ]; then
            echo "CI completed but did not succeed; failing deployment."
            exit 1
          elif [ "$ci_result" -eq 2 ]; then
            echo "CI did not complete successfully within the expected time window."
            echo "Evaluating whether to auto-rerun this Deploy workflow instead of requiring a new tag..."

            ATTEMPT="${GITHUB_RUN_ATTEMPT:-1}"
            MAX_ATTEMPTS="${DEPLOY_AUTO_RERUN_MAX_ATTEMPTS:-3}"

            echo "Current Deploy run attempt: $ATTEMPT (max auto-rerun attempts: $MAX_ATTEMPTS)"

            if [ "$ATTEMPT" -lt "$MAX_ATTEMPTS" ]; then
              echo "Requesting auto-rerun of this Deploy workflow via GitHub Actions API..."
              curl -sS -X POST \
                -H "Authorization: Bearer ${GITHUB_TOKEN}" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/repos/${OWNER}/${REPO}/actions/runs/${GITHUB_RUN_ID}/rerun" \
                || echo "Warning: failed to request auto-rerun via GitHub API."

              echo "Exiting with failure so that the next attempt can pick up fresh CI results."
            else
              echo "Maximum auto-rerun attempts ($MAX_ATTEMPTS) reached; not scheduling another rerun."
            fi

            exit 1
          fi

          dp_result=0
          if ! wait_for_workflow "Docker Publish"; then
            dp_result=$?
          fi

          if [ "$dp_result" -eq 1 ]; then
            echo "Docker Publish completed but did not succeed; failing deployment."
            exit 1
          elif [ "$dp_result" -eq 2 ]; then
            echo "Docker Publish did not complete successfully within the expected time window."
            echo "Evaluating whether to auto-rerun this Deploy workflow instead of requiring a new tag..."

            ATTEMPT="${GITHUB_RUN_ATTEMPT:-1}"
            MAX_ATTEMPTS="${DEPLOY_AUTO_RERUN_MAX_ATTEMPTS:-3}"

            echo "Current Deploy run attempt: $ATTEMPT (max auto-rerun attempts: $MAX_ATTEMPTS)"

            if [ "$ATTEMPT" -lt "$MAX_ATTEMPTS" ]; then
              echo "Requesting auto-rerun of this Deploy workflow via GitHub Actions API..."
              curl -sS -X POST \
                -H "Authorization: Bearer ${GITHUB_TOKEN}" \
                -H "Accept: application/vnd.github+json" \
                "https://api.github.com/repos/${OWNER}/${REPO}/actions/runs/${GITHUB_RUN_ID}/rerun" \
                || echo "Warning: failed to request auto-rerun via GitHub API."

              echo "Exiting with failure so that the next attempt can pick up fresh Docker Publish results."
            else
              echo "Maximum auto-rerun attempts ($MAX_ATTEMPTS) reached; not scheduling another rerun."
            fi

            exit 1
          fi

          # Check Codecov coverage from main branch (hard gate)
          # Uses Codecov API v2 to get actual coverage percentage
          # Falls back to CI workflow success if Codecov API is unavailable
          echo "Checking Codecov coverage for main branch..."
          check_codecov_coverage() {
            local max_attempts=5
            local sleep_seconds=20
            local min_coverage=78  # Codecov reports ~2% lower than local due to line vs statement counting
            
            for attempt in $(seq 1 "$max_attempts"); do
              echo "Attempt $attempt/$max_attempts: Querying Codecov API..."
              
              # Query Codecov API v2 for main branch coverage
              codecov_response=$(curl -sS --connect-timeout 10 --max-time 30 \
                "https://codecov.io/api/v2/github/${OWNER}/repos/${REPO}/commits?branch=main" \
                2>/dev/null || echo '{"error":"api_unavailable"}')
              
              # Check for API errors
              if echo "$codecov_response" | grep -q "error\|upstream connect error"; then
                echo "Codecov API unavailable or returned error."
                if [ "$attempt" -lt "$max_attempts" ]; then
                  echo "Waiting ${sleep_seconds}s before retry..."
                  sleep "$sleep_seconds"
                  continue
                fi
                echo "Codecov API unavailable after $max_attempts attempts."
                echo "Falling back to CI workflow success check..."
                # If CI workflow passed, we trust its coverage gate (80% enforced in Makefile)
                return 0
              fi
              
              
              # Determine which color is currently active
              # Extract coverage from the latest commit
              coverage=$(echo "$codecov_response" | jq -r '.results[0].totals.coverage // empty')
              commit_sha=$(echo "$codecov_response" | jq -r '.results[0].commitid // empty')
              
              if [ -n "$coverage" ] && [ "$coverage" != "null" ]; then
                coverage_int=${coverage%.*}
                echo "Codecov coverage for main branch: ${coverage}% (commit: ${commit_sha:0:7})"
                
                if [ "$coverage_int" -ge "$min_coverage" ]; then
                  echo "✓ Codecov coverage ${coverage}% meets minimum ${min_coverage}%"
                  return 0
                else
                  echo "✗ Codecov coverage ${coverage}% is below minimum ${min_coverage}%"
                  echo "Please improve unit test coverage before deploying."
                  return 1
                fi
              else
                echo "No Codecov coverage data available yet for main branch."
              fi
              
              if [ "$attempt" -lt "$max_attempts" ]; then
                echo "Waiting ${sleep_seconds}s for Codecov to process coverage..."
                sleep "$sleep_seconds"
              fi
            done
            
            echo "[WARN] Codecov coverage data not available after $((max_attempts * sleep_seconds))s."
            echo "Falling back to CI workflow success check (80% coverage enforced in Makefile)."
            return 0
          }
          
          if ! check_codecov_coverage; then
            echo "Codecov coverage check failed; blocking deployment."
            exit 1
          fi

          # Soft, non-blocking checks: log latest status for visibility
          print_workflow_status "Security Scans"
          print_workflow_status "Secrets Healthcheck"
 
  e2e-verify:
    runs-on: ubuntu-latest
    needs: pre-deploy-checks
    steps:
      - uses: actions/checkout@v4
      - name: Setup Go
        uses: actions/setup-go@v6.1.0
        with:
          go-version: '1.25.5'
          cache: true
      - name: Install SOPS and AGE
        run: |
          set -e
          sudo apt-get update
          sudo apt-get install -y age
          SOPS_VERSION="3.8.1"
          curl -L "https://github.com/getsops/sops/releases/download/v${SOPS_VERSION}/sops-v${SOPS_VERSION}.linux.amd64" -o sops
          sudo install -m 0755 sops /usr/local/bin/sops
          sops --version
      - name: Prepare SOPS age key
        env:
          SOPS_AGE_KEY: ${{ secrets.SOPS_AGE_KEY }}
        run: |
          if [ -z "$SOPS_AGE_KEY" ]; then
            echo "SOPS_AGE_KEY not set; skipping SOPS age key setup"
            exit 0
          fi
          mkdir -p ~/.config/sops/age
          printf %s "$SOPS_AGE_KEY" > ~/.config/sops/age/keys.txt
          chmod 600 ~/.config/sops/age/keys.txt
      - name: Decrypt env for E2E (.env from secrets/env.sops.yaml)
        run: |
          if [ ! -f secrets/env.sops.yaml ]; then
            echo "secrets/env.sops.yaml not found; skipping decrypt-env"
            exit 0
          fi
          make decrypt-env
      - name: Run minimal CI E2E tests (pre-deploy gate)
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          OPENROUTER_API_KEY_2: ${{ secrets.OPENROUTER_API_KEY_2 }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          E2E_SMOKE: "1"
        run: |
          make decrypt-test-cv
          LOG_DIR="artifacts/ci-e2e-logs-$(date +%Y%m%d%H%M%S)"
          APP_PORT="${PORT:-8080}"
          DOCKER_COMPOSE_FILES="docker-compose.yml" \
            make run-e2e-ci E2E_CLEAR_DUMP=true E2E_START_SERVICES=true \
              E2E_BASE_URL="http://localhost:${APP_PORT}/v1" \
              E2E_LOG_DIR="${LOG_DIR}" E2E_PARALLEL=1
          make clean-test-cv

  deploy:
    runs-on: ubuntu-latest
    needs: [pre-deploy-checks, e2e-verify, security-gate, infra-dns, infra-vps]
    if: |
      always() &&
      needs.pre-deploy-checks.outputs.should_deploy == 'true' &&
      needs.e2e-verify.result == 'success' &&
      needs.security-gate.result == 'success'
    environment:
      name: production
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install SOPS and AGE
        run: |
          set -e
          sudo apt-get update
          sudo apt-get install -y age
          SOPS_VERSION="3.8.1"
          curl -L "https://github.com/getsops/sops/releases/download/v${SOPS_VERSION}/sops-v${SOPS_VERSION}.linux.amd64" -o sops
          sudo install -m 0755 sops /usr/local/bin/sops
          sops --version

      - name: Prepare SOPS age key
        env:
          SOPS_AGE_KEY: ${{ secrets.SOPS_AGE_KEY }}
        run: |
          mkdir -p ~/.config/sops/age
          printf %s "$SOPS_AGE_KEY" > ~/.config/sops/age/keys.txt
          chmod 600 ~/.config/sops/age/keys.txt

      - name: Set up SSH key
        env:
          SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY }}
        run: |
          mkdir -p ~/.ssh && chmod 700 ~/.ssh
          printf %s "$SSH_PRIVATE_KEY" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          
          # Add server to known_hosts for security
          ssh-keyscan -H ${{ secrets.SSH_HOST }} >> ~/.ssh/known_hosts
          
          # Test connection
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} echo "Connection successful"

      - name: Create deployment directory
        run: |
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} "sudo rm -rf ~/ai-cv-evaluator/deploy && mkdir -p ~/ai-cv-evaluator/deploy && sudo chown -R \$(whoami):\$(whoami) ~/ai-cv-evaluator/deploy"
      
      - name: Decrypt production .env and upload compose/configs
        run: |
          # Decrypt .env.production via Makefile target (requires SOPS installed above)
          if [ -f secrets/env.production.sops.yaml ]; then
            make decrypt-env-production
          fi
          scp docker-compose.prod.yml ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }}:~/ai-cv-evaluator/
          # Debug local file content
          echo "=== Local content of app-https.conf ==="
          cat deploy/nginx/prod-conf.d/app-https.conf
          echo "=== End local content ==="

          # Fix authelia directory permissions before scp (may be owned by Docker)
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} "sudo chown -R \$USER:\$USER ~/ai-cv-evaluator/deploy/authelia 2>/dev/null || mkdir -p ~/ai-cv-evaluator/deploy/authelia"
          
          scp -r deploy/ ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }}:~/ai-cv-evaluator/
          if [ -f .env.production ]; then
            scp .env.production ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }}:~/ai-cv-evaluator/
          fi
          # Ensure Grafana container (UID 472) can read the mounted files
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} "chmod -R o+rX ~/ai-cv-evaluator/deploy/ || true"
      
      - name: Debug file content on server
        run: |
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} '
            ls -la ~/ai-cv-evaluator/deploy/nginx/prod-conf.d/
            echo "=== Content of app-https.conf ==="
            cat ~/ai-cv-evaluator/deploy/nginx/prod-conf.d/app-https.conf || echo "File not found"
            echo "=== End content ==="
          '
      - name: Ensure Docker is available on server
        run: |
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} '
            set -e
            if ! command -v docker >/dev/null 2>&1; then
              echo "Docker not found on server; attempting installation via convenience script..."
              if command -v curl >/dev/null 2>&1; then
                if command -v sudo >/dev/null 2>&1; then
                  curl -fsSL https://get.docker.com | sudo sh
                else
                  curl -fsSL https://get.docker.com | sh
                fi
              else
                echo "curl is not available on the server; please install Docker manually and rerun deploy." >&2
                exit 1
              fi
            fi
            # Ensure current user can access the Docker daemon via the docker group
            if command -v sudo >/dev/null 2>&1; then
              sudo groupadd docker >/dev/null 2>&1 || true
              sudo usermod -aG docker "$USER" || true
            fi
          '

      - name: Login to GHCR on server
        run: |
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} "echo ${{ secrets.GITHUB_TOKEN }} | docker login ghcr.io -u ${{ github.actor }} --password-stdin"

      - name: Ensure certbot auto-renew service is running
        run: |
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} '
            cd ~/ai-cv-evaluator
            # Load production env for docker compose variable interpolation
            if [ -f .env.production ]; then
              set -a
              while IFS= read -r line; do
                [ -z "$line" ] && continue
                case "$line" in \#*) continue ;; esac
                case "$line" in *=*) eval "$line" ;; esac
              done < .env.production
              set +a
            fi
            # Start (or update) the certbot service so its internal renew loop runs on the server
            if docker compose -f docker-compose.prod.yml up -d certbot; then
              echo "certbot service is running (or started)"
            else
              echo "Warning: failed to start certbot service; continuing without blocking deploy" >&2
            fi
          '

      - name: Pre-deployment health check
        run: |
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} '
            cd ~/ai-cv-evaluator
            # Load production env for docker compose variable interpolation (Keycloak, OAuth, etc.)
            if [ -f .env.production ]; then
              set -a
              while IFS= read -r line; do
                [ -z "$line" ] && continue
                case "$line" in
                  \#*)
                    continue
                    ;;
                esac
                case "$line" in
                  *=*)
                    eval "$line"
                    ;;
                esac
              done < .env.production
              set +a
            fi

            # Check if services are running
            if docker compose -f docker-compose.prod.yml ps --services --filter "status=running" | grep -q .; then
              echo "Current services health check..."
              docker compose -f docker-compose.prod.yml exec -T db pg_isready -U postgres || echo "Warning: Postgres not ready"
              docker compose -f docker-compose.prod.yml exec -T redpanda rpk cluster health || echo "Warning: Redpanda health check failed"
            fi
          '
      
      - name: Pull and retag images to release tag
        env:
          IMAGE_TAG: ${{ needs.pre-deploy-checks.outputs.image_tag }}
        run: |
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} '
            set -e
            VERSION='"$IMAGE_TAG"'
            REPO="ghcr.io/${{ github.repository }}"
            max_attempts=20
            sleep_seconds=15

            pull_image() {
              local svc="$1"
              local image_tag="${REPO}-${svc}:${VERSION}"
              echo "Pulling image ${image_tag} (service=${svc})..."
              for attempt in $(seq 1 $max_attempts); do
                if docker pull "${image_tag}"; then
                  echo "Successfully pulled ${image_tag} on attempt ${attempt}"
                  return 0
                fi
                if [ "$attempt" -eq "$max_attempts" ]; then
                  echo "Failed to pull ${image_tag} after ${max_attempts} attempts; giving up."
                  return 1
                fi
                echo "Attempt ${attempt}/${max_attempts} failed for ${image_tag}; sleeping ${sleep_seconds}s..."
                sleep "$sleep_seconds"
              done
            }

            for svc in server worker frontend; do
              pull_image "${svc}"
            done
          '
      
      - name: Pull and retag migration image to release tag
        env:
          IMAGE_TAG: ${{ needs.pre-deploy-checks.outputs.image_tag }}
        run: |
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} '
            set -e
            VERSION='"$IMAGE_TAG"'
            REPO="ghcr.io/${{ github.repository }}"
            max_attempts=20
            sleep_seconds=15

            image_tag="${REPO}-migrate:${VERSION}"
            echo "Pulling image ${image_tag} (migrate)..."
            for attempt in $(seq 1 $max_attempts); do
              if docker pull "${image_tag}"; then
                echo "Successfully pulled ${image_tag} on attempt ${attempt}"
                break
              fi
              if [ "$attempt" -eq "$max_attempts" ]; then
                echo "Failed to pull ${image_tag} after ${max_attempts} attempts; giving up."
                exit 1
              fi
              echo "Attempt ${attempt}/${max_attempts} failed for ${image_tag}; sleeping ${sleep_seconds}s..."
              sleep "$sleep_seconds"
            done
          '
      
      - name: Run database migrations
        run: |
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} '
            cd ~/ai-cv-evaluator
            # Load production env for DB_URL (if present)
            if [ -f .env.production ]; then
              set -a
              while IFS= read -r line; do
                [ -z "$line" ] && continue
                case "$line" in
                  \#*)
                    continue
                    ;;
                esac
                case "$line" in
                  *=*)
                    eval "$line"
                    ;;
                esac
              done < .env.production
              set +a
            fi

            # Ensure DB service is up for backup/migrations
            docker compose -f docker-compose.prod.yml up -d db
            echo "Waiting for Postgres to be ready..."
            for i in {1..30}; do
              if docker compose -f docker-compose.prod.yml exec -T db pg_isready -U postgres >/dev/null 2>&1; then
                echo "Postgres is ready"; break; fi; echo "  Attempt $i/30: waiting for db..."; sleep 2; done

            # Backup database before migration (best-effort)
            docker compose -f docker-compose.prod.yml exec -T db pg_dump -U postgres app > "backup_$(date +%Y%m%d_%H%M%S).sql" || echo "Warning: Backup failed"

            # Run migrations using the dedicated migration container
            docker compose -f docker-compose.prod.yml run --rm migrate
          '
      
      - name: Blue/green deployment (production compose)
        run: |
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} '
            cd ~/ai-cv-evaluator
            # Load production env so docker compose can interpolate required variables
            if [ -f .env.production ]; then
              set -a
              while IFS= read -r line; do
                [ -z "$line" ] && continue
                case "$line" in
                  \#*)
                    continue
                    ;;
                esac
                case "$line" in
                  *=*)
                    eval "$line"
                    ;;
                esac
              done < .env.production
              set +a
            fi

            COLOR_FILE=".active_color"
            if [ -f "$COLOR_FILE" ]; then
              CURRENT_COLOR=$(cat "$COLOR_FILE" | tr -d " \t\r\n")
              case "$CURRENT_COLOR" in
                blue|green) ;;
                *) CURRENT_COLOR="blue" ;;
              esac
            else
              CURRENT_COLOR="blue"
            fi

            if [ "$CURRENT_COLOR" = "blue" ]; then
              NEXT_COLOR="green"
            else
              NEXT_COLOR="blue"
            fi

            echo "Current backend color: $CURRENT_COLOR"
            echo "Next backend color: $NEXT_COLOR"

            # Clean up known conflicting file if it exists
            rm -f deploy/nginx/prod-conf.d/app-http-redirect.conf

            # Update image tags in prod compose file to the release tag
            sed -i "s|image: ghcr.io/.*/ai-cv-evaluator-server:.*|image: ghcr.io/${{ github.repository }}-server:${{ needs.pre-deploy-checks.outputs.image_tag }}|g" docker-compose.prod.yml || true
            sed -i "s|image: ghcr.io/.*/ai-cv-evaluator-worker:.*|image: ghcr.io/${{ github.repository }}-worker:${{ needs.pre-deploy-checks.outputs.image_tag }}|g" docker-compose.prod.yml || true
            sed -i "s|image: ghcr.io/.*/ai-cv-evaluator-frontend:.*|image: ghcr.io/${{ github.repository }}-frontend:${{ needs.pre-deploy-checks.outputs.image_tag }}|g" docker-compose.prod.yml || true
            sed -i "s|image: ghcr.io/.*/ai-cv-evaluator-migrate:.*|image: ghcr.io/${{ github.repository }}-migrate:${{ needs.pre-deploy-checks.outputs.image_tag }}|g" docker-compose.prod.yml || true

            export COMPOSE_FILE=docker-compose.prod.yml

            echo "Bringing up backend_${NEXT_COLOR}, worker, frontend, nginx, and oauth2-proxy services..."
            docker compose up -d "backend_${NEXT_COLOR}" worker frontend nginx oauth2-proxy-app oauth2-proxy-dashboard authelia jaeger grafana prometheus loki promtail otel-collector cadvisor mailpit redpanda-console meta-exporter || { echo "Docker compose up failed!"; exit 1; }

            echo "Waiting for backend_${NEXT_COLOR} service to be running..."
            for i in {1..30}; do
              if docker compose -f docker-compose.prod.yml ps --services --filter "status=running" | grep -q "backend_${NEXT_COLOR}"; then
                echo "backend_${NEXT_COLOR} is running"
                break
              fi
              echo "Attempt $i: Waiting for backend_${NEXT_COLOR} to start..."
              sleep 5
            done

            echo "Force restarting Authelia to refresh configuration..."
            docker compose -f docker-compose.prod.yml restart authelia || echo "Warning: authelia restart failed"
            sleep 10  # Wait for Authelia to fully start

            echo "Force restarting oauth2-proxy services to ensure new configuration is applied..."
            docker compose -f docker-compose.prod.yml restart oauth2-proxy-app oauth2-proxy-dashboard || echo "Warning: oauth2-proxy restart failed"
            
            echo "Force restarting Grafana to ensure new dashboards are loaded..."
            docker compose -f docker-compose.prod.yml restart grafana || echo "Warning: grafana restart failed"
            
            echo "Waiting for oauth2-proxy services to be ready..."
            sleep 10
            for i in {1..10}; do
              if docker compose -f docker-compose.prod.yml ps oauth2-proxy-app | grep -q "running"; then
                echo "oauth2-proxy-app is running"
                break
              fi
              echo "Attempt $i: Waiting for oauth2-proxy-app..."
              sleep 3
            done

            echo "Switching Nginx upstream to backend_${NEXT_COLOR}..."
            sed -i "s|set \$backend_host \".*:8080\";|set \$backend_host \"backend_${NEXT_COLOR}:8080\";|" deploy/nginx/prod-conf.d/app-https.conf.template
            echo "$NEXT_COLOR" > "$COLOR_FILE"

            echo "Restarting Nginx to pick up new upstream..."
            docker compose -f docker-compose.prod.yml restart nginx

            # Wait for health check through Nginx
            echo "Waiting for application to be healthy via Nginx..."
            for i in {1..30}; do
              if docker compose -f docker-compose.prod.yml exec -T nginx curl -fk https://localhost/healthz > /dev/null 2>&1; then
                echo "Backend is healthy through Nginx"
                break
              fi
              echo "Attempt $i: Waiting for backend health check through Nginx..."
              sleep 10
            done

            # Check frontend is accessible
            echo "Checking frontend accessibility..."
            for i in {1..10}; do
              if docker compose -f docker-compose.prod.yml exec -T nginx curl -fk https://localhost/ > /dev/null 2>&1; then
                echo "Frontend is accessible"
                break
              fi
              echo "Attempt $i: Waiting for frontend..."
              sleep 5
            done

            echo "=== docker compose ps ==="
            docker compose -f docker-compose.prod.yml ps
          '

      - name: Enable HTTPS server block and reload Nginx
        run: |
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} '
            cd ~/ai-cv-evaluator
            # Load production env for docker compose
            if [ -f .env.production ]; then
              set -a
              while IFS= read -r line; do
                [ -z "$line" ] && continue
                case "$line" in \#*) continue ;; esac
                case "$line" in *=*) eval "$line" ;; esac
              done < .env.production
              set +a
            fi
            # Use prod-conf.d which is mounted by docker-compose.prod.yml
            if [ -f deploy/nginx/prod-conf.d/app-https.conf.template ]; then
              # Clean up old configs to avoid duplicates/conflicts
              rm -f deploy/nginx/prod-conf.d/*.conf
              
              cp -f deploy/nginx/prod-conf.d/app-https.conf.template deploy/nginx/prod-conf.d/app-https.conf
              if [ -f deploy/nginx/prod-conf.d/app-http-redirect.conf.template ]; then
                cp -f deploy/nginx/prod-conf.d/app-http-redirect.conf.template deploy/nginx/prod-conf.d/app-http.conf
              fi
              # Enable dashboard HTTPS config if present
              if [ -f deploy/nginx/prod-conf.d/dashboard.conf.template ]; then
                cp -f deploy/nginx/prod-conf.d/dashboard.conf.template deploy/nginx/prod-conf.d/dashboard.conf
              fi
              # Enable keycloak HTTPS config if present
              if [ -f deploy/nginx/prod-conf.d/keycloak.conf.template ]; then
                cp -f deploy/nginx/prod-conf.d/keycloak.conf.template deploy/nginx/prod-conf.d/keycloak.conf
              fi
              # Reload Nginx to apply changes - fail if configuration is invalid
              # Restart Nginx to apply changes (reload resulted in lost listeners previously)
              docker compose -f docker-compose.prod.yml restart nginx
            fi
          '
      
      - name: Post-deployment verification (production)
        run: |
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} '
            cd ~/ai-cv-evaluator
            # Load production env for docker compose logs/ps
            if [ -f .env.production ]; then
              set -a
              while IFS= read -r line; do
                [ -z "$line" ] && continue
                case "$line" in
                  \#*)
                    continue
                    ;;
                esac
                case "$line" in
                  *=*)
                    eval "$line"
                    ;;
                esac
              done < .env.production
              set +a
            fi
            
            # Check all services are running
            echo "=== Service Status ==="
            docker compose -f docker-compose.prod.yml ps
            
            # Check application health endpoints (via Nginx)
            echo "=== Health Checks ==="
            curl -f http://localhost/healthz && echo "✓ Health check passed"
            curl -f http://localhost/readyz && echo "✓ Readiness check passed"
            
            # Check logs for any immediate errors
            COLOR_FILE=".active_color"
            ACTIVE_COLOR="blue"
            if [ -f "$COLOR_FILE" ]; then
              ACTIVE_COLOR=$(cat "$COLOR_FILE" | tr -d " \t\r\n")
              case "$ACTIVE_COLOR" in
                blue|green) ;;
                *) ACTIVE_COLOR="blue" ;;
              esac
            fi
            BACKEND_SERVICE="backend_${ACTIVE_COLOR}"

            echo "=== Recent Server Logs (${BACKEND_SERVICE}) ==="
            docker compose -f docker-compose.prod.yml logs --tail=50 "${BACKEND_SERVICE}"
            echo "=== Recent Worker Logs ==="
            docker compose -f docker-compose.prod.yml logs --tail=50 worker
            echo "=== Recent Frontend Logs ==="
            docker compose -f docker-compose.prod.yml logs --tail=50 frontend || echo "No frontend logs"
            echo "=== Recent Nginx Logs ==="
            docker compose -f docker-compose.prod.yml logs --tail=50 nginx || echo "No nginx logs"
            echo "=== Recent OAuth2-Proxy App Logs ==="
            docker compose -f docker-compose.prod.yml logs --tail=50 oauth2-proxy-app || echo "No oauth2-proxy-app logs"
            echo "=== Recent Keycloak Logs ==="
            docker compose -f docker-compose.prod.yml logs --tail=30 keycloak || echo "No keycloak logs"
            
            # Check oauth2 endpoint is responding
            echo "=== OAuth2 Proxy Health Check ==="
            curl -sI http://localhost/oauth2/start 2>&1 | head -5 || echo "Warning: oauth2 start endpoint check failed"
          '
      - name: Cleanup old images
        run: |
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} '
            # Remove old images (keep last 3)
            docker images ghcr.io/${{ github.repository }}-server --format "table {{.Tag}}\t{{.ID}}" | tail -n +4 | awk "{print $2}" | xargs -r docker rmi || true
            docker images ghcr.io/${{ github.repository }}-worker --format "table {{.Tag}}\t{{.ID}}" | tail -n +4 | awk "{print $2}" | xargs -r docker rmi || true
            docker images ghcr.io/${{ github.repository }}-frontend --format "table {{.Tag}}\t{{.ID}}" | tail -n +4 | awk "{print $2}" | xargs -r docker rmi || true
            
            # Clean up unused images and volumes
            docker system prune -f
          '

  validate-production:
    runs-on: ubuntu-latest
    needs: deploy
    if: always() && needs.deploy.result == 'success'
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: admin-frontend/package-lock.json

      - name: Install dependencies
        working-directory: admin-frontend
        run: npm ci

      - name: Install Playwright browsers
        working-directory: admin-frontend
        run: npx playwright install chromium --with-deps

      - name: Setup SSH key for validation
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H ${{ secrets.SSH_HOST }} >> ~/.ssh/known_hosts 2>/dev/null

      - name: Wait for production to be ready
        run: |
          echo "Waiting for production services to be ready..."
          MAX_ATTEMPTS=30
          READY=0

          # Use SSH to check health locally on the server (bypasses Cloudflare WAF/bot protection)
          for i in $(seq 1 "$MAX_ATTEMPTS"); do
            # Capture detailed output to debug connection issues
            OUTPUT=$(ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} 'docker exec ai-cv-evaluator-nginx-1 curl -skv -w "\n%{http_code}" https://localhost/healthz' 2>&1)
            HTTP_CODE=$(echo "$OUTPUT" | tail -n1)
            
            if [ "$HTTP_CODE" = "200" ]; then
              echo "✓ Production health check passed via SSH (HTTP $HTTP_CODE)"
              READY=1
              break
            fi
            
            echo "Attempt $i/$MAX_ATTEMPTS: /healthz returned HTTP '$HTTP_CODE' via SSH; waiting..."
            echo "Curl output snippet:"
            echo "$OUTPUT" | tail -n 10 | sed 's/^/  /'
            sleep 10
          done

          if [ "$READY" -ne 1 ]; then
            echo "Production did not become ready after $((MAX_ATTEMPTS * 10)) seconds; failing validation."
            exit 1
          fi

      - name: Validate production health endpoints
        run: |
          echo "=== Production Health Validation (via SSH to bypass Cloudflare) ==="
          
          # Health check via SSH
          echo "Checking /healthz..."
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} 'docker exec ai-cv-evaluator-nginx-1 curl -sk https://localhost/healthz' && echo " ✓ /healthz OK"
          
          # Readiness check via SSH
          echo "Checking /readyz..."
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} 'docker exec ai-cv-evaluator-nginx-1 curl -sk https://localhost/readyz' && echo " ✓ /readyz OK"
          
          # OpenAPI spec via SSH
          echo "Checking /openapi.yaml..."
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} 'docker exec ai-cv-evaluator-nginx-1 curl -sk https://localhost/openapi.yaml | head -5' && echo " ✓ /openapi.yaml OK"

      - name: Validate services via SSH (Grafana, Prometheus, Mailpit)
        run: |
          echo "=== Service Validation via SSH ==="
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} '
            cd ~/ai-cv-evaluator
            
            echo "Checking running containers..."
            docker compose -f docker-compose.prod.yml ps --format "table {{.Name}}\t{{.Status}}" | head -20
            
            echo ""
            echo "Checking Grafana alerting rules..."
            RULES=$(curl -sfk https://localhost/grafana/api/v1/provisioning/alert-rules 2>/dev/null | head -c 100)
            if [ -n "$RULES" ]; then
              echo "✓ Grafana alerting rules accessible"
            else
              echo "⚠ Grafana alerting rules check failed"
            fi
            
            echo ""
            echo "Checking Prometheus..."
            PROM=$(curl -sfk https://localhost/prometheus/api/v1/status/config 2>/dev/null | head -c 100)
            if [ -n "$PROM" ]; then
              echo "✓ Prometheus accessible"
            else
              echo "⚠ Prometheus check failed"
            fi
            
            echo ""
            echo "Checking Mailpit..."
            MAIL=$(curl -sfk https://localhost/mailpit/api/v1/messages 2>/dev/null | head -c 100)
            if [ -n "$MAIL" ]; then
              echo "✓ Mailpit accessible"
            else
              echo "⚠ Mailpit check failed"
            fi
            
            echo ""
            echo "Checking Jaeger..."
            JAEGER=$(curl -sfk https://localhost/jaeger/search 2>/dev/null | head -c 100)
            if [ -n "$JAEGER" ]; then
              echo "✓ Jaeger accessible"
            else
              echo "⚠ Jaeger check failed"
            fi

            echo ""
            echo "Checking Redpanda Console..."
            REDPANDA=$(curl -sfk https://localhost/redpanda/ 2>/dev/null | head -c 100)
            if [ -n "$REDPANDA" ]; then
              echo "✓ Redpanda Console accessible"
            else
              echo "⚠ Redpanda Console check failed"
            fi

            echo ""
            echo "✓ Service validation completed"
          '

      - name: Trigger test alert and verify Mailpit via SSH
        run: |
          echo "=== Triggering test alert and verifying Mailpit via SSH ==="
          ssh ${{ secrets.SSH_USER }}@${{ secrets.SSH_HOST }} 'bash -s' << 'EOFSCRIPT'
          set -e
          cd ~/ai-cv-evaluator
          
          # Set up Docker network for internal queries
          NETWORK="ai-cv-evaluator_default"
          docker pull curlimages/curl:latest >/dev/null 2>&1 || true
          
          echo "Clearing all Mailpit messages before test..."
          # DELETE without body clears all messages
          docker run --rm --network "$NETWORK" curlimages/curl -s -X DELETE 'http://mailpit:8025/mailpit/api/v1/messages' 2>/dev/null || true
          
          echo "Verifying Mailpit is cleared..."
          INITIAL_RESP=$(docker run --rm --network "$NETWORK" curlimages/curl -s 'http://mailpit:8025/mailpit/api/v1/messages' 2>/dev/null || echo "")
          INITIAL_TOTAL=$(echo "$INITIAL_RESP" | grep -o '"total":[0-9]*' | head -1 | sed 's/[^0-9]//g')
          [ -z "$INITIAL_TOTAL" ] && INITIAL_TOTAL=0
          echo "Mailpit message count after clearing: $INITIAL_TOTAL"
          
          echo "Generating HTTP errors to trigger HighHttpErrorRate..."
          # Hit backend via 'app' alias (same as Prometheus scrape target) to ensure metrics are recorded
          echo "Using Docker network: $NETWORK"
          # Generate errors over a longer period to ensure Prometheus captures them across multiple scrapes
          # Prometheus scrapes every 15s, so we generate errors for ~30s
          for i in $(seq 1 60); do
            HTTP_CODE=$(docker run --rm --network "$NETWORK" curlimages/curl -s -o /dev/null -w "%{http_code}" "http://app:8080/v1/__nonexistent_path_for_errors" 2>/dev/null || echo "000")
            [ $((i % 10)) -eq 0 ] && echo "Request $i: HTTP $HTTP_CODE"
            sleep 0.5
          done
          
          echo "Waiting 20s for Prometheus to scrape the new error metrics..."
          sleep 20
          
          echo "Checking Prometheus metrics via Docker network (bypassing SSO)..."
          # Query Prometheus directly on internal network to bypass oauth2-proxy SSO
          # Note: Prometheus is configured with --web.route-prefix=/prometheus
          HTTP_METRICS=$(docker run --rm --network "$NETWORK" curlimages/curl -s 'http://prometheus:9090/prometheus/api/v1/query?query=http_requests_total' 2>/dev/null || echo "")
          echo "http_requests_total metric sample:"
          echo "$HTTP_METRICS" | head -c 500
          
          ERROR_RATE=$(docker run --rm --network "$NETWORK" curlimages/curl -s 'http://prometheus:9090/prometheus/api/v1/query?query=sum(rate(http_requests_total{status!="OK"}[5m]))' 2>/dev/null || echo "")
          echo "Error rate query result:"
          echo "$ERROR_RATE" | head -c 300
          
          # Check Prometheus scrape targets
          echo "Checking Prometheus targets..."
          TARGETS=$(docker run --rm --network "$NETWORK" curlimages/curl -s 'http://prometheus:9090/prometheus/api/v1/targets' 2>/dev/null || echo "")
          echo "Prometheus targets:"
          echo "$TARGETS" | head -c 500
          
          echo "Waiting for HighHttpErrorRate alert to fire in Prometheus..."
          ALERT_FIRING=0
          for attempt in $(seq 1 15); do
            # Use /api/v1/alerts endpoint which shows all active alerts with their state
            ALL_ALERTS=$(docker run --rm --network "$NETWORK" curlimages/curl -s 'http://prometheus:9090/prometheus/api/v1/alerts' 2>/dev/null || echo "")
            # Check if HighHttpErrorRate is in firing state
            if echo "$ALL_ALERTS" | grep -q '"alertname":"HighHttpErrorRate"' && echo "$ALL_ALERTS" | grep -q '"state":"firing"'; then
              ALERT_FIRING=1
              echo "HighHttpErrorRate is firing (attempt $attempt)."
              echo "$ALL_ALERTS" | head -c 500
              break
            fi
            echo "Attempt $attempt/15: alert not firing yet, waiting 10s..."
            sleep 10
          done
          
          if [ "$ALERT_FIRING" -ne 1 ]; then
            echo "HighHttpErrorRate alert did not fire within expected time."
            echo "All active alerts:"
            echo "$ALL_ALERTS" | head -c 500
            echo "WARNING: Alert didn't fire, but continuing with deployment..."
          fi
          
          if [ "$ALERT_FIRING" -eq 1 ]; then
            echo "Waiting for alert email to arrive in Mailpit via Docker network..."
            EMAIL_RECEIVED=0
            for attempt in $(seq 1 18); do
              RESP=$(docker run --rm --network "$NETWORK" curlimages/curl -s 'http://mailpit:8025/mailpit/api/v1/messages' 2>/dev/null || echo "")
              TOTAL=$(echo "$RESP" | grep -o '"total":[0-9]*' | head -1 | sed 's/[^0-9]//g')
              [ -z "$TOTAL" ] && TOTAL=0
              if [ "$TOTAL" -gt "$INITIAL_TOTAL" ]; then
                EMAIL_RECEIVED=1
                echo "Mailpit message count increased from $INITIAL_TOTAL to $TOTAL"
                echo "Sample messages payload:"
                echo "$RESP" | head -c 500 || true
                break
              fi
              echo "Attempt $attempt/18: no new emails yet (total=$TOTAL), waiting 10s..."
              sleep 10
            done
            
            if [ "$EMAIL_RECEIVED" -ne 1 ]; then
              echo "WARNING: Alert fired but no email arrived in Mailpit within expected time."
              echo "This may indicate SMTP configuration issues."
            else
              echo "SUCCESS: Alert pipeline verified end-to-end (HighHttpErrorRate -> Grafana -> Mailpit)."
            fi
          else
            echo "Skipping Mailpit email check since alert did not fire."
            echo "Alerting infrastructure validation: PARTIAL (services accessible, alerts need tuning)"
          fi
          
          echo "=== Production alerting validation completed ==="
          EOFSCRIPT

      - name: Validate SSL certificates
        run: |
          echo "=== SSL Certificate Validation ==="
          
          # Check main domain
          echo "Checking SSL for ai-cv-evaluator.web.id..."
          echo | openssl s_client -connect ai-cv-evaluator.web.id:443 -servername ai-cv-evaluator.web.id 2>/dev/null | openssl x509 -noout -dates || echo "Warning: SSL check failed"
          
          # Check dashboard domain
          echo "Checking SSL for dashboard.ai-cv-evaluator.web.id..."
          echo | openssl s_client -connect dashboard.ai-cv-evaluator.web.id:443 -servername dashboard.ai-cv-evaluator.web.id 2>/dev/null | openssl x509 -noout -dates || echo "Warning: SSL check failed"

      - name: Validate DNS records
        run: |
          echo "=== DNS Record Validation ==="
          
          echo "Checking ai-cv-evaluator.web.id..."
          dig +short ai-cv-evaluator.web.id A
          
          echo "Checking dashboard.ai-cv-evaluator.web.id..."
          dig +short dashboard.ai-cv-evaluator.web.id A
          
          echo "Checking keycloak.ai-cv-evaluator.web.id..."
          dig +short keycloak.ai-cv-evaluator.web.id A

      - name: Check Grafana accessibility
        run: |
          echo "=== Observability Stack Check ==="
          
          # These require SSO, so we just check they return something (not 5xx)
          HTTP_CODE=$(curl -sL -o /dev/null -w "%{http_code}" "${{ env.PRODUCTION_URL }}/grafana/")
          if [[ "$HTTP_CODE" == "302" || "$HTTP_CODE" == "200" ]]; then
            echo "✓ Grafana endpoint responding (HTTP $HTTP_CODE)"
          else
            echo "⚠ Grafana returned unexpected code: $HTTP_CODE"
          fi

      - name: Disable Cloudflare proxy for E2E tests
        env:
          CF_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CF_ZONE_ID: ${{ secrets.CLOUDFLARE_ZONE_ID }}
        run: |
          echo "=== Disabling Cloudflare proxy for E2E tests ==="
          
          if [ -z "${CF_API_TOKEN}" ] || [ -z "${CF_ZONE_ID}" ]; then
            echo "⚠ Cloudflare credentials not set, skipping proxy disable"
            exit 0
          fi
          
          api_base="https://api.cloudflare.com/client/v4"
          records=("ai-cv-evaluator.web.id" "dashboard.ai-cv-evaluator.web.id" "keycloak.ai-cv-evaluator.web.id")
          
          for name in "${records[@]}"; do
            echo "Disabling proxy for ${name}..."
            existing=$(curl -s -X GET "${api_base}/zones/${CF_ZONE_ID}/dns_records?type=A&name=${name}" \
              -H "Authorization: Bearer ${CF_API_TOKEN}" \
              -H "Content-Type: application/json")
            
            id=$(echo "${existing}" | jq -r '.result[0].id // empty')
            ip=$(echo "${existing}" | jq -r '.result[0].content // empty')
            
            if [ -n "${id}" ] && [ -n "${ip}" ]; then
              data=$(jq -n --arg name "${name}" --arg ip "${ip}" '{type:"A", name:$name, content:$ip, ttl:300, proxied:false}')
              curl -s -X PUT "${api_base}/zones/${CF_ZONE_ID}/dns_records/${id}" \
                -H "Authorization: Bearer ${CF_API_TOKEN}" \
                -H "Content-Type: application/json" \
                -d "${data}" | jq '.success'
              echo "✓ Proxy disabled for ${name}"
            fi
          done
          
          # Wait for DNS propagation
          echo "Waiting 30s for DNS propagation..."
          sleep 30

      - name: Run Playwright E2E tests for CV evaluation and AI metrics
        working-directory: admin-frontend
        env:
          E2E_BASE_URL: ${{ env.PRODUCTION_URL }}
          SSO_USERNAME: ${{ secrets.SSO_USERNAME }}
          SSO_PASSWORD: ${{ secrets.SSO_PASSWORD }}
        run: |
          echo "=== Running Playwright E2E tests against production ==="
          echo "Base URL: $E2E_BASE_URL"
          
          # Check if SSO credentials are available
          if [ -z "$SSO_PASSWORD" ]; then
            echo "⚠ SSO_PASSWORD not set, skipping Playwright E2E tests"
            echo "To enable: Add SSO_USERNAME and SSO_PASSWORD secrets to GitHub repository"
            exit 0
          fi
          
          # Run the real-eval test to trigger actual CV evaluations
          npx playwright test real-eval.spec.ts --reporter=list --timeout=180000 || {
            echo "⚠ real-eval test failed, but continuing with validation..."
          }
          
          npx playwright test comprehensive-e2e.spec.ts -g "AI Metrics" --reporter=list --timeout=120000 || {
            echo "⚠ AI Metrics dashboard tests had issues, but continuing..."
          }
          
          # Run Grafana dashboard validation (Docker metrics)
          npx playwright test grafana.spec.ts --reporter=list --timeout=60000 || {
            echo "⚠ Grafana dashboard verification failed, but continuing..."
          }
          
          echo "=== Playwright E2E tests completed ==="

      - name: Re-enable Cloudflare proxy after E2E tests
        if: always()
        env:
          CF_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CF_ZONE_ID: ${{ secrets.CLOUDFLARE_ZONE_ID }}
        run: |
          echo "=== Re-enabling Cloudflare proxy after E2E tests ==="
          
          if [ -z "${CF_API_TOKEN}" ] || [ -z "${CF_ZONE_ID}" ]; then
            echo "⚠ Cloudflare credentials not set, skipping proxy enable"
            exit 0
          fi
          
          api_base="https://api.cloudflare.com/client/v4"
          records=("ai-cv-evaluator.web.id" "dashboard.ai-cv-evaluator.web.id" "keycloak.ai-cv-evaluator.web.id")
          
          for name in "${records[@]}"; do
            echo "Enabling proxy for ${name}..."
            existing=$(curl -s -X GET "${api_base}/zones/${CF_ZONE_ID}/dns_records?type=A&name=${name}" \
              -H "Authorization: Bearer ${CF_API_TOKEN}" \
              -H "Content-Type: application/json")
            
            id=$(echo "${existing}" | jq -r '.result[0].id // empty')
            ip=$(echo "${existing}" | jq -r '.result[0].content // empty')
            
            if [ -n "${id}" ] && [ -n "${ip}" ]; then
              data=$(jq -n --arg name "${name}" --arg ip "${ip}" '{type:"A", name:$name, content:$ip, ttl:300, proxied:true}')
              curl -s -X PUT "${api_base}/zones/${CF_ZONE_ID}/dns_records/${id}" \
                -H "Authorization: Bearer ${CF_API_TOKEN}" \
                -H "Content-Type: application/json" \
                -d "${data}" | jq '.success'
              echo "✓ Proxy enabled for ${name}"
            fi
          done
          
          echo "Cloudflare proxy re-enabled for all domains"

      - name: Generate validation report
        if: always()
        run: |
          echo "=== Production Validation Summary ==="
          echo "Timestamp: $(date -u +%Y-%m-%dT%H:%M:%SZ)"
          echo "Production URL: ${{ env.PRODUCTION_URL }}"
          echo "Dashboard URL: ${{ env.DASHBOARD_URL }}"
          echo ""
          echo "Validation completed. Check above logs for details."

  notify-validation-result:
    runs-on: ubuntu-latest
    needs: validate-production
    if: always()
    steps:
      - name: Report validation status
        run: |
          if [[ "${{ needs.validate-production.result }}" == "success" ]]; then
            echo "✅ Production validation PASSED"
          else
            echo "❌ Production validation FAILED or had issues"
            echo "Please check the workflow logs for details"
          fi

  cloudflare-dns-sync:
    runs-on: ubuntu-latest
    needs: deploy
    if: always() && needs.deploy.result == 'success'
    env:
      CF_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
      CF_ZONE_ID: ${{ secrets.CLOUDFLARE_ZONE_ID }}
      SSH_HOST: ${{ secrets.SSH_HOST }}
      TARGET_IP_OVERRIDE: ${{ github.event.inputs.target_ip }}
    steps:
      - name: Install jq
        run: |
          sudo apt-get update
          sudo apt-get install -y jq

      - name: Upsert DNS records for production hostnames
        run: |
          set -euo pipefail

          if [ -z "${CF_API_TOKEN}" ] || [ -z "${CF_ZONE_ID}" ]; then
            echo "CLOUDFLARE_API_TOKEN or CLOUDFLARE_ZONE_ID not set" >&2
            exit 1
          fi

          TARGET_IP="${TARGET_IP_OVERRIDE:-$SSH_HOST}"
          if [ -z "${TARGET_IP}" ]; then
            echo "TARGET_IP is empty; set SSH_HOST secret or provide target_ip input" >&2
            exit 1
          fi

          records=(
            "ai-cv-evaluator.web.id"
            "dashboard.ai-cv-evaluator.web.id"
            "keycloak.ai-cv-evaluator.web.id"
          )

          api_base="https://api.cloudflare.com/client/v4"

          for name in "${records[@]}"; do
            echo "Syncing A record for ${name} -> ${TARGET_IP}"

            existing=$(curl -s -X GET "${api_base}/zones/${CF_ZONE_ID}/dns_records?type=A&name=${name}" \
              -H "Authorization: Bearer ${CF_API_TOKEN}" \
              -H "Content-Type: application/json")

            id=$(echo "${existing}" | jq -r '.result[0].id // empty')

            data=$(jq -n --arg name "${name}" --arg ip "${TARGET_IP}" '{type:"A", name:$name, content:$ip, ttl:300, proxied:true}')

            if [ -n "${id}" ]; then
              echo "Updating existing record ${id} for ${name}"
              curl -s -X PUT "${api_base}/zones/${CF_ZONE_ID}/dns_records/${id}" \
                -H "Authorization: Bearer ${CF_API_TOKEN}" \
                -H "Content-Type: application/json" \
                -d "${data}" | jq '.success, .errors'
            else
              echo "Creating new record for ${name}"
              curl -s -X POST "${api_base}/zones/${CF_ZONE_ID}/dns_records" \
                -H "Authorization: Bearer ${CF_API_TOKEN}" \
                -H "Content-Type: application/json" \
                -d "${data}" | jq '.success, .errors'
            fi
          done

      - name: Purge Cloudflare cache
        run: |
          echo "Purging Cloudflare cache to ensure fresh content..."
          response=$(curl -s -X POST "https://api.cloudflare.com/client/v4/zones/${CF_ZONE_ID}/purge_cache" \
            -H "Authorization: Bearer ${CF_API_TOKEN}" \
            -H "Content-Type: application/json" \
            --data '{"purge_everything":true}')
          
          success=$(echo "$response" | jq -r '.success')
          if [ "$success" = "true" ]; then
            echo "✓ Cloudflare cache purged successfully"
          else
            echo "⚠ Cache purge failed:"
            echo "$response" | jq '.errors'
          fi

  # Slack notifications intentionally omitted; see Windsurf rules for rationale
  infra-dns:
    runs-on: ubuntu-latest
    needs: pre-deploy-checks
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init
        run: terraform init
        working-directory: terraform/cloudflare

      - name: Terraform Apply
        env:
          TF_VAR_cloudflare_api_token: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          TF_VAR_server_ip: ${{ secrets.SSH_HOST }}
          TF_VAR_domain_name: "ai-cv-evaluator.web.id"
        run: terraform apply -auto-approve
        working-directory: terraform/cloudflare
  infra-vps:
    runs-on: ubuntu-latest
    needs: pre-deploy-checks
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init
        run: terraform init
        working-directory: terraform/vps

      - name: Terraform Apply (Provision Server)
        env:
          TF_VAR_server_ip: ${{ secrets.SSH_HOST }}
          TF_VAR_ssh_user: ${{ secrets.SSH_USER }}
          TF_VAR_ssh_private_key: ${{ secrets.SSH_PRIVATE_KEY }}
        run: terraform apply -auto-approve
        working-directory: terraform/vps


